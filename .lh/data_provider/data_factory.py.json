{
    "sourceFile": "data_provider/data_factory.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 19,
            "patches": [
                {
                    "date": 1731075084024,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1731075092086,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,9 +30,9 @@\n         data_set = Data(\n             root_path=args.root_path,\n             data_path=args.data_path,\n             flag=flag,\n-            size=[args.seq_len, args.input_token_len, args.test_pred_len],\n+            size=[args.seq_len, args.input_token_len, args.output_token_len],\n             nonautoregressive=args.nonautoregressive,\n             test_flag=args.test_flag,\n             subset_rand_ratio=args.subset_rand_ratio\n         )\n"
                },
                {
                    "date": 1731678477260,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,11 @@\n from data_provider.data_loader import UnivariateDatasetBenchmark, MultivariateDatasetBenchmark, Global_Temp, Global_Wind, Dataset_ERA5_Pretrain, Dataset_ERA5_Pretrain_Test, UTSD, UTSD_Npy\n from torch.utils.data import DataLoader\n from torch.utils.data.distributed import DistributedSampler\n+import torch\n+from torch.nn.utils.rnn import pad_sequence\n \n+\n data_dict = {\n     'UnivariateDatasetBenchmark': UnivariateDatasetBenchmark,\n     'MultivariateDatasetBenchmark': MultivariateDatasetBenchmark,\n     'Global_Temp': Global_Temp,\n@@ -13,8 +16,35 @@\n     'Utsd_Npy': UTSD_Npy\n }\n \n \n+def collate_fn(batch):\n+    \"\"\"\n+    Collate function that pads examples of different lengths.\n+    \n+    Args:\n+        batch (list): A list of examples from the dataset.\n+    \n+    Returns:\n+        A tuple of:\n+        - padded_inputs: A padded tensor of the input features.\n+        - input_lengths: A tensor of the original lengths of the inputs.\n+        - targets: A padded tensor of the target labels.\n+        - target_lengths: A tensor of the original lengths of the targets.\n+    \"\"\"\n+    # Unpack the examples\n+    inputs, targets = zip(*batch)\n+    \n+    # Pad the input sequences\n+    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n+    input_lengths = torch.tensor([len(x) for x in inputs])\n+    \n+    # Pad the target sequences\n+    padded_targets = pad_sequence(targets, batch_first=True, padding_value=0)\n+    target_lengths = torch.tensor([len(x) for x in targets])\n+    \n+    return padded_inputs, input_lengths, padded_targets, target_lengths\n+\n def data_provider(args, flag):\n     Data = data_dict[args.data]\n \n     if flag in ['test', 'val']:\n"
                },
                {
                    "date": 1731678625690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,19 +31,18 @@\n         - targets: A padded tensor of the target labels.\n         - target_lengths: A tensor of the original lengths of the targets.\n     \"\"\"\n     # Unpack the examples\n-    inputs, targets = zip(*batch)\n+    seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n     \n     # Pad the input sequences\n-    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n-    input_lengths = torch.tensor([len(x) for x in inputs])\n+    padded_seq_x = pad_sequence(seq_x, batch_first=True, padding_value=0)\n+    lengths = torch.tensor([len(x) for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_targets = pad_sequence(targets, batch_first=True, padding_value=0)\n-    target_lengths = torch.tensor([len(x) for x in targets])\n+    padded_seq_y = pad_sequence(seq_y, batch_first=True, padding_value=0)\n     \n-    return padded_inputs, input_lengths, padded_targets, target_lengths\n+    return padded_seq_x, padded_seq_y, seq_x_mark, seq_y_mark, lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n \n"
                },
                {
                    "date": 1731678694500,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,7 +94,8 @@\n             shuffle=shuffle_flag,\n             num_workers=args.num_workers,\n             persistent_workers=True,\n             pin_memory=True,\n-            drop_last=drop_last\n+            drop_last=drop_last,\n+            collate_fn=collate_fn if 'Utsd' in args.data else None\n         )\n     return data_set, data_loader\n"
                },
                {
                    "date": 1731682119160,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,9 +34,9 @@\n     # Unpack the examples\n     seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n     \n     # Pad the input sequences\n-    padded_seq_x = pad_sequence(seq_x, batch_first=True, padding_value=0)\n+    padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([len(x) for x in seq_x])\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(seq_y, batch_first=True, padding_value=0)\n"
                },
                {
                    "date": 1731682139364,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,9 +35,9 @@\n     seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n-    lengths = torch.tensor([len(x) for x in seq_x])\n+    lengths = torch.tensor([len(x.shape[1]) for x in seq_x])\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(seq_y, batch_first=True, padding_value=0)\n     \n"
                },
                {
                    "date": 1731682156353,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,12 +35,12 @@\n     seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n-    lengths = torch.tensor([len(x.shape[1]) for x in seq_x])\n+    lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_seq_y = pad_sequence(seq_y, batch_first=True, padding_value=0)\n+    padded_seq_y = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n     \n     return padded_seq_x, padded_seq_y, seq_x_mark, seq_y_mark, lengths\n \n def data_provider(args, flag):\n"
                },
                {
                    "date": 1731682188839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,9 +40,9 @@\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n     \n-    return padded_seq_x, padded_seq_y, seq_x_mark, seq_y_mark, lengths\n+    return padded_seq_x, padded_seq_y, torch.from_numpy(seq_x_mark), torch.from_numpy(seq_y_mark), lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n \n"
                },
                {
                    "date": 1731682318910,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,9 +38,9 @@\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_seq_y = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n+    padded_seq_y = pad_sequence(torch.from_numpy(seq_y), batch_first=True, padding_value=0)\n     \n     return padded_seq_x, padded_seq_y, torch.from_numpy(seq_x_mark), torch.from_numpy(seq_y_mark), lengths\n \n def data_provider(args, flag):\n"
                },
                {
                    "date": 1731682433388,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,8 +32,9 @@\n         - target_lengths: A tensor of the original lengths of the targets.\n     \"\"\"\n     # Unpack the examples\n     seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n+    print(seq_x)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n"
                },
                {
                    "date": 1731724899240,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n         - targets: A padded tensor of the target labels.\n         - target_lengths: A tensor of the original lengths of the targets.\n     \"\"\"\n     # Unpack the examples\n-    seq_x, seq_y, seq_x_mark, seq_y_mark = zip(*batch)\n+    seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*examples)))\n     print(seq_x)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n"
                },
                {
                    "date": 1731724904869,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n         - targets: A padded tensor of the target labels.\n         - target_lengths: A tensor of the original lengths of the targets.\n     \"\"\"\n     # Unpack the examples\n-    seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*examples)))\n+    seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n     print(seq_x)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n"
                },
                {
                    "date": 1731725101722,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,13 +35,13 @@\n     seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n     print(seq_x)\n     \n     # Pad the input sequences\n-    padded_seq_x = pad_sequence(torch.from_numpy(seq_x), batch_first=True, padding_value=0)\n+    padded_seq_x = pad_sequence(torch.Tensor(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_seq_y = pad_sequence(torch.from_numpy(seq_y), batch_first=True, padding_value=0)\n+    padded_seq_y = pad_sequence(torch.Tensor(seq_y), batch_first=True, padding_value=0)\n     \n     return padded_seq_x, padded_seq_y, torch.from_numpy(seq_x_mark), torch.from_numpy(seq_y_mark), lengths\n \n def data_provider(args, flag):\n"
                },
                {
                    "date": 1731725110581,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,9 +41,9 @@\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(torch.Tensor(seq_y), batch_first=True, padding_value=0)\n     \n-    return padded_seq_x, padded_seq_y, torch.from_numpy(seq_x_mark), torch.from_numpy(seq_y_mark), lengths\n+    return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n \n"
                },
                {
                    "date": 1731725487784,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,17 +32,16 @@\n         - target_lengths: A tensor of the original lengths of the targets.\n     \"\"\"\n     # Unpack the examples\n     seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n-    print(seq_x)\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence(torch.Tensor(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(torch.Tensor(seq_y), batch_first=True, padding_value=0)\n-    \n+    print(padded_seq_x.shape, padded_seq_y.shape)\n     return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n"
                },
                {
                    "date": 1731725495000,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,9 +39,9 @@\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n     padded_seq_y = pad_sequence(torch.Tensor(seq_y), batch_first=True, padding_value=0)\n-    print(padded_seq_x.shape, padded_seq_y.shape)\n+    print(padded_seq_x.shape, padded_seq_y.shape, lengths.shape)\n     return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n"
                },
                {
                    "date": 1731727035028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,10 @@\n from torch.utils.data import DataLoader\n from torch.utils.data.distributed import DistributedSampler\n import torch\n from torch.nn.utils.rnn import pad_sequence\n+import numpy as np\n \n-\n data_dict = {\n     'UnivariateDatasetBenchmark': UnivariateDatasetBenchmark,\n     'MultivariateDatasetBenchmark': MultivariateDatasetBenchmark,\n     'Global_Temp': Global_Temp,\n@@ -34,13 +34,13 @@\n     # Unpack the examples\n     seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n     \n     # Pad the input sequences\n-    padded_seq_x = pad_sequence(torch.Tensor(seq_x), batch_first=True, padding_value=0)\n+    padded_seq_x = pad_sequence(np.array(seq_x), batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_seq_y = pad_sequence(torch.Tensor(seq_y), batch_first=True, padding_value=0)\n+    padded_seq_y = pad_sequence(np.array(seq_y), batch_first=True, padding_value=0)\n     print(padded_seq_x.shape, padded_seq_y.shape, lengths.shape)\n     return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n \n def data_provider(args, flag):\n"
                },
                {
                    "date": 1731727153415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,13 +34,13 @@\n     # Unpack the examples\n     seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n     \n     # Pad the input sequences\n-    padded_seq_x = pad_sequence(np.array(seq_x), batch_first=True, padding_value=0)\n+    padded_seq_x = pad_sequence([torch.tensor(x) for x in seq_x], batch_first=True, padding_value=0)\n+    padded_seq_y = pad_sequence([torch.tensor(y) for y in seq_y], batch_first=True, padding_value=0)\n     lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n     # Pad the target sequences\n-    padded_seq_y = pad_sequence(np.array(seq_y), batch_first=True, padding_value=0)\n     print(padded_seq_x.shape, padded_seq_y.shape, lengths.shape)\n     return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n \n def data_provider(args, flag):\n"
                },
                {
                    "date": 1731727226480,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,14 +35,18 @@\n     seq_x, seq_y, seq_x_mark, seq_y_mark = tuple(map(list, zip(*batch)))\n     \n     # Pad the input sequences\n     padded_seq_x = pad_sequence([torch.tensor(x) for x in seq_x], batch_first=True, padding_value=0)\n+    lengths = torch.tensor([len(x) for x in seq_x])\n+    \n+    # Pad the target sequences\n     padded_seq_y = pad_sequence([torch.tensor(y) for y in seq_y], batch_first=True, padding_value=0)\n-    lengths = torch.tensor([x.shape[1] for x in seq_x])\n     \n-    # Pad the target sequences\n-    print(padded_seq_x.shape, padded_seq_y.shape, lengths.shape)\n-    return padded_seq_x, padded_seq_y, torch.Tensor(seq_x_mark), torch.Tensor(seq_y_mark), lengths\n+    # Convert seq_x_mark and seq_y_mark to tensors\n+    seq_x_mark = torch.stack([torch.tensor(mark) for mark in seq_x_mark])\n+    seq_y_mark = torch.stack([torch.tensor(mark) for mark in seq_y_mark])\n+    \n+    return padded_seq_x, padded_seq_y, seq_x_mark, seq_y_mark, lengths\n \n def data_provider(args, flag):\n     Data = data_dict[args.data]\n \n"
                }
            ],
            "date": 1731075084024,
            "name": "Commit-0",
            "content": "from data_provider.data_loader import UnivariateDatasetBenchmark, MultivariateDatasetBenchmark, Global_Temp, Global_Wind, Dataset_ERA5_Pretrain, Dataset_ERA5_Pretrain_Test, UTSD, UTSD_Npy\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\n\ndata_dict = {\n    'UnivariateDatasetBenchmark': UnivariateDatasetBenchmark,\n    'MultivariateDatasetBenchmark': MultivariateDatasetBenchmark,\n    'Global_Temp': Global_Temp,\n    'Global_Wind': Global_Wind,\n    'Era5_Pretrain': Dataset_ERA5_Pretrain,\n    'Era5_Pretrain_Test': Dataset_ERA5_Pretrain_Test,\n    'Utsd': UTSD,\n    'Utsd_Npy': UTSD_Npy\n}\n\n\ndef data_provider(args, flag):\n    Data = data_dict[args.data]\n\n    if flag in ['test', 'val']:\n        shuffle_flag = False\n        drop_last = False\n        batch_size = args.batch_size\n    else:\n        shuffle_flag = True\n        drop_last = False\n        batch_size = args.batch_size\n\n    if flag in ['train', 'val']:\n        data_set = Data(\n            root_path=args.root_path,\n            data_path=args.data_path,\n            flag=flag,\n            size=[args.seq_len, args.input_token_len, args.test_pred_len],\n            nonautoregressive=args.nonautoregressive,\n            test_flag=args.test_flag,\n            subset_rand_ratio=args.subset_rand_ratio\n        )\n    else:\n        data_set = Data(\n            root_path=args.root_path,\n            data_path=args.data_path,\n            flag=flag,\n            size=[args.test_seq_len, args.input_token_len, args.test_pred_len],\n            nonautoregressive=args.nonautoregressive,\n            test_flag=args.test_flag,\n            subset_rand_ratio=args.subset_rand_ratio\n        )\n    print(flag, len(data_set))\n    if args.ddp:\n        train_datasampler = DistributedSampler(data_set, shuffle=shuffle_flag)\n        data_loader = DataLoader(\n            data_set,\n            batch_size=batch_size,\n            sampler=train_datasampler,\n            num_workers=args.num_workers,\n            persistent_workers=True,\n            pin_memory=True,\n            drop_last=drop_last,\n        )\n    else:\n        data_loader = DataLoader(\n            data_set,\n            batch_size=batch_size,\n            shuffle=shuffle_flag,\n            num_workers=args.num_workers,\n            persistent_workers=True,\n            pin_memory=True,\n            drop_last=drop_last\n        )\n    return data_set, data_loader\n"
        }
    ]
}